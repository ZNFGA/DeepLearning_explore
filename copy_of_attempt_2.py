# -*- coding: utf-8 -*-
"""Copy of Attempt 2

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GS5qbIUcaq9SIOaUoA7zF-pb45XR1TVR
"""

# =============================================================
# SEL 1: INSTALL DEPENDENSI
# =============================================================
!pip install torch torchvision torchinfo scikit-learn pandas matplotlib Pillow tqdm

# =============================================================
# SEL 2: IMPORT & SET SEED â€” REPRODUCIBILITY + ENV VAR
# =============================================================
import os
os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'  # ðŸ”¥ SOLUSI ERROR cuBLAS

import torch
import torch.nn as nn
import torchvision.transforms as transforms
from torchvision.models import efficientnet_b0
from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import classification_report, confusion_matrix, f1_score
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import random

# --- SET SEED ---
def set_seed(seed=42):
    torch.manual_seed(seed)
    np.random.seed(seed)
    random.seed(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
    torch.use_deterministic_algorithms(True)

set_seed()

device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"Using device: {device}")

# =============================================================
# SEL 3: MOUNT DRIVE & LOAD PATH
# =============================================================
from google.colab import drive
drive.mount("/content/drive")

BASE_PATH = "/content/drive/MyDrive/at least I am try/IF25-4041-dataset"
TRAIN_IMG_DIR = os.path.join(BASE_PATH, "train")
TEST_IMG_DIR  = os.path.join(BASE_PATH, "test")
TRAIN_CSV_PATH = os.path.join(BASE_PATH, "train.csv")
TEST_CSV_PATH  = os.path.join(BASE_PATH, "test.csv")

print("âœ… Train images:", TRAIN_IMG_DIR)
print("âœ… Train CSV   :", TRAIN_CSV_PATH)
print("âœ… Test images :", TEST_IMG_DIR)
print("âœ… Test CSV    :", TEST_CSV_PATH)

# =============================================================
# SEL 4: LOAD DATA & LABEL MAPPING
# =============================================================
train_df = pd.read_csv(TRAIN_CSV_PATH)

LABEL_MAP = {
    'nasi_goreng': 0,
    'rendang': 1,
    'soto_ayam': 2,
    'bakso': 3,
    'gado_gado': 4
}
REVERSE_LABEL_MAP = {v: k for k, v in LABEL_MAP.items()}

image_paths = [os.path.join(TRAIN_IMG_DIR, fname) for fname in train_df['filename']]
labels = [LABEL_MAP[label] for label in train_df['label']]

print(f"âœ… Total gambar train: {len(image_paths)}")
print(f"ðŸ“Š Distribusi label:")
print(pd.Series(train_df['label']).value_counts().to_dict())

# =============================================================
# SEL 5: CUSTOM DATASET â€” DENGAN PERBAIKAN TRANSPARANSI
# =============================================================
class FoodDataset(Dataset):
    def __init__(self, image_paths, labels, transform=None):
        self.image_paths = image_paths
        self.labels = labels
        self.transform = transform

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        try:
            img = Image.open(self.image_paths[idx])
            if img.mode == 'P' and 'transparency' in img.info:
                img = img.convert('RGBA')
            if img.mode == 'RGBA':
                background = Image.new('RGB', img.size, (255, 255, 255))
                background.paste(img, mask=img.split()[-1])
                img = background
            elif img.mode != 'RGB':
                img = img.convert('RGB')
        except Exception as e:
            print(f"âš ï¸ Error loading {self.image_paths[idx]}: {e}")
            img = Image.new('RGB', (224, 224))

        label = self.labels[idx]
        if self.transform:
            img = self.transform(img)
        return img, label

# =============================================================
# SEL 6: AUGMENTASI â€” AMAN DAN EFEKTIF
# =============================================================
train_transform = transforms.Compose([
    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),
    transforms.AutoAugment(transforms.AutoAugmentPolicy.IMAGENET),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

val_transform = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

print("âœ… Transformasi siap digunakan.")

# =============================================================
# SEL 7: STRATIFIED K-FOLD SPLIT
# =============================================================
skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
fold_splits = []

print("ðŸ” Membagi data menjadi 5 fold secara stratified...")

for fold, (train_idx, val_idx) in enumerate(skf.split(image_paths, labels)):
    fold_splits.append({
        'train_idx': train_idx,
        'val_idx': val_idx
    })
    print(f"  Fold {fold}: Train={len(train_idx)} | Val={len(val_idx)}")

import pickle
with open('fold_splits.pkl', 'wb') as f:
    pickle.dump(fold_splits, f)

print("âœ… Split selesai & disimpan ke 'fold_splits.pkl'")

# =============================================================
# SEL 8: MODEL â€” PLAIN-34 (TANPA RESIDUAL CONNECTION)
# Sesuai TOR: arsitektur ResNet-34 yang telah dihilangkan skip connection-nya
# =============================================================

import torch.nn.functional as F

class PlainBlock(nn.Module):
    """
    Plain Block without residual connection.
    This is equivalent to a ResNet BasicBlock but without the skip connection.
    """
    def __init__(self, in_channels, out_channels, stride=1, downsample=None):
        super(PlainBlock, self).__init__()
        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3,
                              stride=stride, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(out_channels)
        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3,
                              stride=1, padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(out_channels)
        self.downsample = downsample

    def forward(self, x):
        identity = x
        out = F.relu(self.bn1(self.conv1(x)))
        out = self.bn2(self.conv2(out))
        # âŒ TIDAK ADA residual connection: out += identity
        if self.downsample is not None:
            identity = self.downsample(identity)
        # Langsung ReLU tanpa tambah identity
        out = F.relu(out)
        return out


class Plain34(nn.Module):
    def __init__(self, num_classes=5):
        super(Plain34, self).__init__()
        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)
        self.bn1 = nn.BatchNorm2d(64)
        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)

        self.stage1 = self._make_stage(64, 64, 3, stride=1)
        self.stage2 = self._make_stage(64, 128, 4, stride=2)
        self.stage3 = self._make_stage(128, 256, 6, stride=2)
        self.stage4 = self._make_stage(256, 512, 3, stride=2)

        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        self.fc = nn.Linear(512, num_classes)
        self._initialize_weights()

    def _make_stage(self, in_channels, out_channels, num_blocks, stride):
        downsample = None
        if stride != 1 or in_channels != out_channels:
            downsample = nn.Sequential(
                nn.Conv2d(in_channels, out_channels, 1, stride, bias=False),
                nn.BatchNorm2d(out_channels)
            )
        layers = [PlainBlock(in_channels, out_channels, stride, downsample)]
        for _ in range(1, num_blocks):
            layers.append(PlainBlock(out_channels, out_channels))
        return nn.Sequential(*layers)

    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
            elif isinstance(m, nn.BatchNorm2d):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.Linear):
                nn.init.normal_(m.weight, 0, 0.01)
                nn.init.constant_(m.bias, 0)

    def forward(self, x):
        x = F.relu(self.bn1(self.conv1(x)))
        x = self.maxpool(x)
        x = self.stage1(x)
        x = self.stage2(x)
        x = self.stage3(x)
        x = self.stage4(x)
        x = self.avgpool(x)
        x = torch.flatten(x, 1)
        return self.fc(x)


def get_model():
    """Mengembalikan model Plain-34 untuk 5 kelas makanan Indonesia."""
    return Plain34(num_classes=5)


# Cek jumlah parameter
model_dummy = get_model()
from torchinfo import summary
summary(model_dummy, input_size=(1, 3, 224, 224), device='cpu')

# =============================================================
# SEL 9: TRAINING â€” 1 FASE, 1 SPLIT, 10 EPOCH (CEPAT!)
# =============================================================
from torch.optim import AdamW
from tqdm import tqdm

def train_one_epoch(model, dataloader, criterion, optimizer, device):
    model.train()
    total_loss = 0
    correct = 0
    total = 0
    for images, labels in tqdm(dataloader, desc="Training", leave=False):
        images, labels = images.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
        optimizer.step()
        total_loss += loss.item()
        _, preds = outputs.max(1)
        correct += preds.eq(labels).sum().item()
        total += labels.size(0)
    return total_loss / len(dataloader), correct / total

def validate(model, dataloader, criterion, device):
    model.eval()
    total_loss = 0
    correct = 0
    total = 0
    all_preds = []
    all_labels = []
    with torch.no_grad():
        for images, labels in tqdm(dataloader, desc="Validating", leave=False):
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            loss = criterion(outputs, labels)
            total_loss += loss.item()
            _, preds = outputs.max(1)
            correct += preds.eq(labels).sum().item()
            total += labels.size(0)
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
    f1 = f1_score(all_labels, all_preds, average='macro')
    return total_loss / len(dataloader), correct / total, f1, all_preds, all_labels

# === GANTI DARI 5-FOLD KE 1 SPLIT SAJA ===
from sklearn.model_selection import train_test_split

print("ðŸ”€ Membagi data: 80% train, 20% val (stratified)...")
train_idx, val_idx = train_test_split(
    range(len(image_paths)),
    test_size=0.2,
    stratify=labels,
    random_state=42
)

train_dataset = FoodDataset(
    [image_paths[i] for i in train_idx],
    [labels[i] for i in train_idx],
    transform=train_transform
)
val_dataset = FoodDataset(
    [image_paths[i] for i in val_idx],
    [labels[i] for i in val_idx],
    transform=val_transform
)

train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=0)

# === INISIALISASI MODEL ===
model = get_model().to(device)
criterion = nn.CrossEntropyLoss()
optimizer = AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)

print("\nðŸš€ MULAI TRAINING â€” 1 FASE, 10 EPOCH, 1 SPLIT...")

best_val_f1 = 0
best_epoch = 0

# Jalankan hanya 10 epoch
for epoch in range(10):
    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)
    val_loss, val_acc, val_f1, _, _ = validate(model, val_loader, criterion, device)

    print(f"Epoch {epoch+1}/10 | Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} | Val Loss: {val_loss:.4f} Acc: {val_acc:.4f} F1: {val_f1:.4f}")

    # Simpan model terbaik berdasarkan F1
    if val_f1 > best_val_f1:
        best_val_f1 = val_f1
        best_epoch = epoch
        torch.save(model.state_dict(), 'model_best.pth')

print(f"\nâœ… Training selesai! Model terbaik di epoch {best_epoch+1} dengan F1 = {best_val_f1:.4f}")
torch.save(torch.load('model_best.pth'), 'model.pth')
print("ðŸ’¾ model.pth telah disimpan!")

# =============================================================
# SEL 10: VALIDASI AKHIR â€” CONFUSION MATRIX & PER-CLASS F1
# =============================================================
model = get_model().to(device)
model.load_state_dict(torch.load('model.pth'))
model.eval()

val_dataset = FoodDataset(
    [image_paths[i] for i in fold_splits[best_fold]['val_idx']],
    [labels[i] for i in fold_splits[best_fold]['val_idx']],
    transform=val_transform
)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)

_, _, _, all_preds, all_labels = validate(model, val_loader, criterion, device)

# Classification Report
print("\nðŸ“Š === PER-CLASS METRICS (Fold Terbaik) ===")
target_names = list(LABEL_MAP.keys())
print(classification_report(all_labels, all_preds, target_names=target_names, digits=4))

# Confusion Matrix
cm = confusion_matrix(all_labels, all_preds)
plt.figure(figsize=(8,6))
plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
plt.title('Confusion Matrix (Fold Terbaik)')
plt.colorbar()
tick_marks = np.arange(len(target_names))
plt.xticks(tick_marks, target_names, rotation=45)
plt.yticks(tick_marks, target_names)
plt.ylabel('True Label')
plt.xlabel('Predicted Label')
plt.tight_layout()
plt.savefig('confusion_matrix.png', dpi=150)
plt.show()

print("âœ… Confusion matrix disimpan ke 'confusion_matrix.png'")